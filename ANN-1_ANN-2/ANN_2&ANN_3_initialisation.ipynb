{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_2&ANN_3_initialisation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Initialisation and Training of ANN-2 and ANN-3"
      ],
      "metadata": {
        "id": "u-uVdYENHMUm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5XLAvmfD3ls"
      },
      "outputs": [],
      "source": [
        "# importing necessary public modules\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import Input, Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for GPU\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BzDr0qacEABg",
        "outputId": "83cf16af-0701-4ba0-b48f-5ee2032eb86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connecting to google drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(\"/content/drive/My Drive/content\")\n",
        "\n",
        "# loading of Black-Scholes data\n",
        "data = np.genfromtxt('bs_data.csv', delimiter=',')\n",
        "\n",
        "# data prep\n",
        "\n",
        "# inputs: converting spot price + strike price to moneyness (s/k)\n",
        "inputs = data[:,:5] \n",
        "X = np.array([np.array([x[0]/x[1], x[2],x[3],x[4]])for x in inputs])\n",
        "\n",
        "# outputs: scaling the prices byt the strike price (p/k)\n",
        "y_calls = np.array(data[:,-2]) / data[:,1]\n",
        "y_puts = np.array(data[:,-1]) / data[:,1]\n",
        "\n",
        "# training data\n",
        "X_train = X[:900000]\n",
        "y_calls_train = y_calls[:900000]\n",
        "y_puts_train = y_puts[:900000]\n",
        "\n",
        "# validation data\n",
        "X_val = X[900000:950000]\n",
        "y_calls_val = y_calls[900000:950000]\n",
        "y_puts_val = y_puts[900000:950000]\n",
        "\n",
        "# testing data\n",
        "X_test = X[950000:]\n",
        "y_calls_test = y_calls[950000:]\n",
        "y_puts_test = y_puts[950000:]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_calls_train.shape)\n",
        "print(y_puts_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_calls_val.shape)\n",
        "print(y_puts_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_calls_test.shape)\n",
        "print(y_puts_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQYLi8RDEEie",
        "outputId": "634e3866-4442-4b6a-ac32-1d86468c5fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "(900000, 4)\n",
            "(900000,)\n",
            "(900000,)\n",
            "(50000, 4)\n",
            "(50000,)\n",
            "(50000,)\n",
            "(50000, 4)\n",
            "(50000,)\n",
            "(50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN-2 model initialisation\n",
        "inputs = Input(shape=(4,), name='input')\n",
        "x = Dense(600, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
        "x = Dense(600, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "call = Dense(1, name='call_output')(x)\n",
        "\n",
        "ann_2 = Model(inputs=inputs, outputs=call)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
        "ann_2.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "ann_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7pKswXR3lyW",
        "outputId": "d61aa08a-eb5e-418c-f0fa-bc85c77d10a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 600)               3000      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 600)               360600    \n",
            "                                                                 \n",
            " call_output (Dense)         (None, 1)                 601       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 364,201\n",
            "Trainable params: 364,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN-2 training\n",
        "ann_2.fit(X_train, y_calls_train,\n",
        "                validation_data = (X_val, y_calls_val),\n",
        "                epochs=200, batch_size=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdM9r8qW3sO0",
        "outputId": "32a605e2-173f-46ff-bf67-7c9e3c042af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 0.0141 - val_loss: 4.2717e-04\n",
            "Epoch 2/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.3986e-04 - val_loss: 2.9286e-05\n",
            "Epoch 3/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.3548e-05 - val_loss: 5.4303e-06\n",
            "Epoch 4/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 3.3247e-06 - val_loss: 1.9131e-06\n",
            "Epoch 5/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5516e-06 - val_loss: 1.1013e-06\n",
            "Epoch 6/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0372e-06 - val_loss: 9.7913e-07\n",
            "Epoch 7/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 7.8926e-07 - val_loss: 6.9201e-07\n",
            "Epoch 8/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.5893e-07 - val_loss: 8.4476e-07\n",
            "Epoch 9/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.5339e-07 - val_loss: 4.7471e-07\n",
            "Epoch 10/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.0180e-07 - val_loss: 6.0125e-07\n",
            "Epoch 11/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.5169e-07 - val_loss: 3.5684e-07\n",
            "Epoch 12/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.1484e-07 - val_loss: 3.1587e-07\n",
            "Epoch 13/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 3.8307e-07 - val_loss: 2.9175e-07\n",
            "Epoch 14/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 3.5523e-07 - val_loss: 3.9402e-07\n",
            "Epoch 15/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 3.4064e-07 - val_loss: 3.0381e-07\n",
            "Epoch 16/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 3.2106e-07 - val_loss: 2.3981e-07\n",
            "Epoch 17/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 3.0793e-07 - val_loss: 3.2474e-07\n",
            "Epoch 18/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.8651e-07 - val_loss: 4.9604e-07\n",
            "Epoch 19/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.8039e-07 - val_loss: 2.0398e-07\n",
            "Epoch 20/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.6855e-07 - val_loss: 2.0125e-07\n",
            "Epoch 21/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.6337e-07 - val_loss: 1.8427e-07\n",
            "Epoch 22/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.5576e-07 - val_loss: 1.9399e-07\n",
            "Epoch 23/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.4252e-07 - val_loss: 1.8602e-07\n",
            "Epoch 24/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.3946e-07 - val_loss: 2.4038e-07\n",
            "Epoch 25/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.3761e-07 - val_loss: 1.7230e-07\n",
            "Epoch 26/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.2885e-07 - val_loss: 1.6681e-07\n",
            "Epoch 27/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.2571e-07 - val_loss: 1.9163e-07\n",
            "Epoch 28/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.2122e-07 - val_loss: 2.8647e-07\n",
            "Epoch 29/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.1505e-07 - val_loss: 1.8207e-07\n",
            "Epoch 30/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.0793e-07 - val_loss: 1.9575e-07\n",
            "Epoch 31/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.0799e-07 - val_loss: 2.1606e-07\n",
            "Epoch 32/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 2.0114e-07 - val_loss: 2.6020e-07\n",
            "Epoch 33/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.9950e-07 - val_loss: 1.6101e-07\n",
            "Epoch 34/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.9921e-07 - val_loss: 2.0878e-07\n",
            "Epoch 35/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.9449e-07 - val_loss: 2.2902e-07\n",
            "Epoch 36/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.9124e-07 - val_loss: 1.2582e-07\n",
            "Epoch 37/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.8981e-07 - val_loss: 1.7503e-07\n",
            "Epoch 38/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.8744e-07 - val_loss: 1.2594e-07\n",
            "Epoch 39/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.8030e-07 - val_loss: 4.6064e-07\n",
            "Epoch 40/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.8223e-07 - val_loss: 2.1736e-07\n",
            "Epoch 41/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.7803e-07 - val_loss: 2.3161e-07\n",
            "Epoch 42/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.7641e-07 - val_loss: 1.1587e-07\n",
            "Epoch 43/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.7540e-07 - val_loss: 2.4413e-07\n",
            "Epoch 44/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.7347e-07 - val_loss: 1.6986e-07\n",
            "Epoch 45/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.7107e-07 - val_loss: 1.1516e-07\n",
            "Epoch 46/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.6726e-07 - val_loss: 1.1972e-07\n",
            "Epoch 47/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.6731e-07 - val_loss: 4.1749e-07\n",
            "Epoch 48/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.6489e-07 - val_loss: 4.0919e-07\n",
            "Epoch 49/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.6277e-07 - val_loss: 1.3511e-07\n",
            "Epoch 50/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.6329e-07 - val_loss: 1.0527e-07\n",
            "Epoch 51/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5710e-07 - val_loss: 1.2252e-07\n",
            "Epoch 52/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5996e-07 - val_loss: 1.2365e-07\n",
            "Epoch 53/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5532e-07 - val_loss: 1.0424e-07\n",
            "Epoch 54/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5687e-07 - val_loss: 1.3701e-07\n",
            "Epoch 55/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5338e-07 - val_loss: 1.4392e-07\n",
            "Epoch 56/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.5229e-07 - val_loss: 1.0561e-07\n",
            "Epoch 57/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5201e-07 - val_loss: 9.5822e-08\n",
            "Epoch 58/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5006e-07 - val_loss: 1.2781e-07\n",
            "Epoch 59/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.5070e-07 - val_loss: 1.0603e-07\n",
            "Epoch 60/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.4715e-07 - val_loss: 9.6439e-08\n",
            "Epoch 61/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.4568e-07 - val_loss: 1.0647e-07\n",
            "Epoch 62/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.4465e-07 - val_loss: 8.9869e-08\n",
            "Epoch 63/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.4445e-07 - val_loss: 5.2763e-07\n",
            "Epoch 64/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.4110e-07 - val_loss: 1.0741e-07\n",
            "Epoch 65/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.4320e-07 - val_loss: 1.2801e-07\n",
            "Epoch 66/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.4279e-07 - val_loss: 9.7880e-08\n",
            "Epoch 67/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.4005e-07 - val_loss: 8.7776e-08\n",
            "Epoch 68/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.3860e-07 - val_loss: 1.2391e-07\n",
            "Epoch 69/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.3598e-07 - val_loss: 9.0631e-08\n",
            "Epoch 70/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.3335e-07 - val_loss: 8.0596e-08\n",
            "Epoch 71/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.3712e-07 - val_loss: 8.2105e-08\n",
            "Epoch 72/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.3270e-07 - val_loss: 9.1880e-08\n",
            "Epoch 73/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.3274e-07 - val_loss: 1.6248e-07\n",
            "Epoch 74/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.3249e-07 - val_loss: 8.4862e-08\n",
            "Epoch 75/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.3173e-07 - val_loss: 8.2411e-08\n",
            "Epoch 76/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.3103e-07 - val_loss: 1.4145e-07\n",
            "Epoch 77/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.2850e-07 - val_loss: 1.2006e-07\n",
            "Epoch 78/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2911e-07 - val_loss: 1.2594e-07\n",
            "Epoch 79/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.2959e-07 - val_loss: 8.1272e-08\n",
            "Epoch 80/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.2494e-07 - val_loss: 2.1040e-07\n",
            "Epoch 81/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2602e-07 - val_loss: 8.0287e-08\n",
            "Epoch 82/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2581e-07 - val_loss: 1.1731e-07\n",
            "Epoch 83/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2643e-07 - val_loss: 1.0452e-07\n",
            "Epoch 84/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2675e-07 - val_loss: 1.1833e-07\n",
            "Epoch 85/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2448e-07 - val_loss: 1.4118e-07\n",
            "Epoch 86/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2170e-07 - val_loss: 8.8722e-08\n",
            "Epoch 87/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.2125e-07 - val_loss: 2.2877e-07\n",
            "Epoch 88/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2284e-07 - val_loss: 7.5243e-08\n",
            "Epoch 89/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2282e-07 - val_loss: 8.1846e-08\n",
            "Epoch 90/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.2169e-07 - val_loss: 7.0135e-08\n",
            "Epoch 91/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1635e-07 - val_loss: 6.8912e-08\n",
            "Epoch 92/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1967e-07 - val_loss: 7.0699e-08\n",
            "Epoch 93/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1998e-07 - val_loss: 1.1331e-07\n",
            "Epoch 94/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1766e-07 - val_loss: 8.6932e-08\n",
            "Epoch 95/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1509e-07 - val_loss: 7.9377e-08\n",
            "Epoch 96/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1791e-07 - val_loss: 1.3985e-07\n",
            "Epoch 97/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1855e-07 - val_loss: 6.8956e-08\n",
            "Epoch 98/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1501e-07 - val_loss: 8.5804e-08\n",
            "Epoch 99/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1555e-07 - val_loss: 1.8636e-07\n",
            "Epoch 100/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1382e-07 - val_loss: 8.5930e-08\n",
            "Epoch 101/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1541e-07 - val_loss: 2.3835e-07\n",
            "Epoch 102/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1220e-07 - val_loss: 1.5781e-07\n",
            "Epoch 103/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1419e-07 - val_loss: 4.7808e-07\n",
            "Epoch 104/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.1243e-07 - val_loss: 1.1619e-07\n",
            "Epoch 105/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1146e-07 - val_loss: 6.7928e-08\n",
            "Epoch 106/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1203e-07 - val_loss: 7.2435e-08\n",
            "Epoch 107/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.1177e-07 - val_loss: 6.5049e-08\n",
            "Epoch 108/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.1147e-07 - val_loss: 6.7067e-08\n",
            "Epoch 109/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0990e-07 - val_loss: 6.3907e-08\n",
            "Epoch 110/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.1042e-07 - val_loss: 6.1886e-08\n",
            "Epoch 111/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0816e-07 - val_loss: 1.9296e-07\n",
            "Epoch 112/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.0803e-07 - val_loss: 7.2638e-08\n",
            "Epoch 113/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0786e-07 - val_loss: 6.0731e-08\n",
            "Epoch 114/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.0628e-07 - val_loss: 6.1907e-08\n",
            "Epoch 115/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0776e-07 - val_loss: 8.8247e-08\n",
            "Epoch 116/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.0827e-07 - val_loss: 7.0783e-08\n",
            "Epoch 117/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0584e-07 - val_loss: 7.9411e-08\n",
            "Epoch 118/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0728e-07 - val_loss: 1.0910e-07\n",
            "Epoch 119/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0350e-07 - val_loss: 7.8204e-08\n",
            "Epoch 120/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0478e-07 - val_loss: 2.1039e-07\n",
            "Epoch 121/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0230e-07 - val_loss: 6.5861e-08\n",
            "Epoch 122/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.0672e-07 - val_loss: 1.3154e-07\n",
            "Epoch 123/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.0290e-07 - val_loss: 6.4827e-08\n",
            "Epoch 124/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0291e-07 - val_loss: 6.0218e-08\n",
            "Epoch 125/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0349e-07 - val_loss: 2.8420e-07\n",
            "Epoch 126/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.0050e-07 - val_loss: 6.2408e-08\n",
            "Epoch 127/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0330e-07 - val_loss: 1.0675e-07\n",
            "Epoch 128/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0188e-07 - val_loss: 7.8394e-08\n",
            "Epoch 129/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0168e-07 - val_loss: 5.6309e-08\n",
            "Epoch 130/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.9709e-08 - val_loss: 6.6075e-08\n",
            "Epoch 131/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 1.0281e-07 - val_loss: 5.6316e-08\n",
            "Epoch 132/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.9993e-08 - val_loss: 6.2490e-08\n",
            "Epoch 133/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0075e-07 - val_loss: 1.3881e-07\n",
            "Epoch 134/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.9876e-08 - val_loss: 5.9850e-08\n",
            "Epoch 135/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 1.0027e-07 - val_loss: 6.0649e-08\n",
            "Epoch 136/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.8242e-08 - val_loss: 7.9248e-08\n",
            "Epoch 137/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.9395e-08 - val_loss: 1.0053e-07\n",
            "Epoch 138/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.8275e-08 - val_loss: 3.1851e-07\n",
            "Epoch 139/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.8350e-08 - val_loss: 6.4886e-08\n",
            "Epoch 140/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.6508e-08 - val_loss: 5.3048e-08\n",
            "Epoch 141/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.6280e-08 - val_loss: 9.0731e-08\n",
            "Epoch 142/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.6287e-08 - val_loss: 8.3239e-08\n",
            "Epoch 143/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.7229e-08 - val_loss: 7.0429e-08\n",
            "Epoch 144/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.7917e-08 - val_loss: 2.8868e-07\n",
            "Epoch 145/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.5903e-08 - val_loss: 1.2156e-07\n",
            "Epoch 146/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.7127e-08 - val_loss: 1.1788e-07\n",
            "Epoch 147/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.6165e-08 - val_loss: 5.1411e-08\n",
            "Epoch 148/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.4632e-08 - val_loss: 5.8658e-08\n",
            "Epoch 149/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.5053e-08 - val_loss: 5.1990e-08\n",
            "Epoch 150/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.3704e-08 - val_loss: 2.1307e-07\n",
            "Epoch 151/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.2369e-08 - val_loss: 6.3123e-08\n",
            "Epoch 152/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.4985e-08 - val_loss: 6.3897e-08\n",
            "Epoch 153/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.2577e-08 - val_loss: 5.2870e-07\n",
            "Epoch 154/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.3786e-08 - val_loss: 5.0020e-08\n",
            "Epoch 155/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.4880e-08 - val_loss: 5.5086e-08\n",
            "Epoch 156/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.3131e-08 - val_loss: 5.3022e-08\n",
            "Epoch 157/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.0854e-08 - val_loss: 5.5773e-08\n",
            "Epoch 158/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.3850e-08 - val_loss: 5.8159e-08\n",
            "Epoch 159/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.3405e-08 - val_loss: 2.1808e-07\n",
            "Epoch 160/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.0204e-08 - val_loss: 1.5805e-07\n",
            "Epoch 161/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.2361e-08 - val_loss: 6.1443e-08\n",
            "Epoch 162/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.0282e-08 - val_loss: 4.8644e-08\n",
            "Epoch 163/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.9237e-08 - val_loss: 1.3755e-07\n",
            "Epoch 164/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.2905e-08 - val_loss: 6.8062e-08\n",
            "Epoch 165/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.0414e-08 - val_loss: 1.0753e-07\n",
            "Epoch 166/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 9.0598e-08 - val_loss: 2.2954e-07\n",
            "Epoch 167/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.7911e-08 - val_loss: 1.3407e-07\n",
            "Epoch 168/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.0183e-08 - val_loss: 7.9896e-08\n",
            "Epoch 169/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.9596e-08 - val_loss: 1.1771e-07\n",
            "Epoch 170/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.8966e-08 - val_loss: 9.8897e-08\n",
            "Epoch 171/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.0231e-08 - val_loss: 5.9965e-08\n",
            "Epoch 172/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.7623e-08 - val_loss: 5.9707e-08\n",
            "Epoch 173/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 9.0444e-08 - val_loss: 5.3264e-08\n",
            "Epoch 174/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.8000e-08 - val_loss: 5.2107e-08\n",
            "Epoch 175/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.5979e-08 - val_loss: 4.7802e-08\n",
            "Epoch 176/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.7795e-08 - val_loss: 5.2441e-08\n",
            "Epoch 177/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 8.7024e-08 - val_loss: 5.4674e-08\n",
            "Epoch 178/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.6692e-08 - val_loss: 4.5540e-08\n",
            "Epoch 179/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 8.7223e-08 - val_loss: 7.4898e-08\n",
            "Epoch 180/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.6439e-08 - val_loss: 1.4363e-07\n",
            "Epoch 181/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.6885e-08 - val_loss: 6.8610e-08\n",
            "Epoch 182/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.6784e-08 - val_loss: 4.5281e-08\n",
            "Epoch 183/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.6315e-08 - val_loss: 4.7309e-08\n",
            "Epoch 184/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.6464e-08 - val_loss: 4.6399e-08\n",
            "Epoch 185/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.5331e-08 - val_loss: 8.3552e-08\n",
            "Epoch 186/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 8.6485e-08 - val_loss: 8.8273e-08\n",
            "Epoch 187/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 8.6074e-08 - val_loss: 1.3329e-07\n",
            "Epoch 188/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.3204e-08 - val_loss: 4.2596e-08\n",
            "Epoch 189/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.4709e-08 - val_loss: 1.1628e-07\n",
            "Epoch 190/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.5549e-08 - val_loss: 4.3733e-08\n",
            "Epoch 191/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.3026e-08 - val_loss: 4.9953e-08\n",
            "Epoch 192/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.5532e-08 - val_loss: 7.8741e-08\n",
            "Epoch 193/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.3470e-08 - val_loss: 1.3741e-07\n",
            "Epoch 194/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.4416e-08 - val_loss: 7.7585e-08\n",
            "Epoch 195/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 8.3398e-08 - val_loss: 4.5601e-08\n",
            "Epoch 196/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 8.3139e-08 - val_loss: 5.8398e-08\n",
            "Epoch 197/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 8.3757e-08 - val_loss: 2.5878e-07\n",
            "Epoch 198/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.2520e-08 - val_loss: 7.7319e-08\n",
            "Epoch 199/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.0692e-08 - val_loss: 6.2050e-08\n",
            "Epoch 200/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 8.5333e-08 - val_loss: 4.2070e-08\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f720072c650>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving as model ANN-2\n",
        "ann_2.save('ANN-2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcejal6XTTcv",
        "outputId": "c0f04ab1-b9f8-481f-a388-935ba9748472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ANN-2/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN-3 initialisation\n",
        "inputs = Input(shape=(4,), name='input')\n",
        "x = Dense(400, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
        "x = Dense(400, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = Dense(400, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "put = Dense(1, name='put_output')(x)\n",
        "\n",
        "ann_3 = Model(inputs=inputs, outputs=put)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-05)\n",
        "ann_3.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "ann_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVK5AC7BPWSA",
        "outputId": "f7fb023a-8dc0-46af-edaf-43c97866204b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 400)               2000      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 400)               160400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 400)               160400    \n",
            "                                                                 \n",
            " put_output (Dense)          (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 323,201\n",
            "Trainable params: 323,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN-3 training\n",
        "ann_3.fit(X_train, y_puts_train,\n",
        "                validation_data = (X_val, y_puts_val),\n",
        "                epochs=200, batch_size=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBeszIbUQKlZ",
        "outputId": "b4daa688-c3c6-4ab0-eb2f-4a692b47c51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 6.3460e-08 - val_loss: 3.7315e-08\n",
            "Epoch 2/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.5392e-08 - val_loss: 3.7756e-08\n",
            "Epoch 3/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.4239e-08 - val_loss: 2.8746e-07\n",
            "Epoch 4/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 6.3775e-08 - val_loss: 3.7643e-08\n",
            "Epoch 5/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.3794e-08 - val_loss: 1.9938e-07\n",
            "Epoch 6/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.3673e-08 - val_loss: 4.4169e-08\n",
            "Epoch 7/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.3398e-08 - val_loss: 5.2605e-08\n",
            "Epoch 8/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 6.2844e-08 - val_loss: 4.0243e-08\n",
            "Epoch 9/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.4025e-08 - val_loss: 3.9610e-08\n",
            "Epoch 10/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 6.2303e-08 - val_loss: 5.2573e-08\n",
            "Epoch 11/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.1851e-08 - val_loss: 5.4578e-08\n",
            "Epoch 12/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.3731e-08 - val_loss: 1.0556e-07\n",
            "Epoch 13/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.1869e-08 - val_loss: 9.7435e-08\n",
            "Epoch 14/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 6.1595e-08 - val_loss: 4.0365e-08\n",
            "Epoch 15/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.1807e-08 - val_loss: 7.2926e-08\n",
            "Epoch 16/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 6.1669e-08 - val_loss: 6.4357e-08\n",
            "Epoch 17/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.2078e-08 - val_loss: 8.9189e-08\n",
            "Epoch 18/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.1658e-08 - val_loss: 3.6576e-08\n",
            "Epoch 19/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.1326e-08 - val_loss: 9.4388e-08\n",
            "Epoch 20/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.1545e-08 - val_loss: 5.0929e-08\n",
            "Epoch 21/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.0039e-08 - val_loss: 4.8495e-08\n",
            "Epoch 22/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.9869e-08 - val_loss: 4.4678e-08\n",
            "Epoch 23/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 6.0606e-08 - val_loss: 4.4255e-08\n",
            "Epoch 24/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.9441e-08 - val_loss: 4.9443e-08\n",
            "Epoch 25/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 6.0055e-08 - val_loss: 4.5651e-08\n",
            "Epoch 26/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.0584e-08 - val_loss: 8.0493e-08\n",
            "Epoch 27/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.9550e-08 - val_loss: 6.6517e-08\n",
            "Epoch 28/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.9620e-08 - val_loss: 3.8380e-08\n",
            "Epoch 29/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.9330e-08 - val_loss: 6.5561e-08\n",
            "Epoch 30/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.9467e-08 - val_loss: 5.2692e-08\n",
            "Epoch 31/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.9628e-08 - val_loss: 4.6253e-08\n",
            "Epoch 32/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 6.0380e-08 - val_loss: 6.0589e-08\n",
            "Epoch 33/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.7472e-08 - val_loss: 6.1895e-08\n",
            "Epoch 34/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.8731e-08 - val_loss: 7.6511e-08\n",
            "Epoch 35/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.9098e-08 - val_loss: 9.7084e-08\n",
            "Epoch 36/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.8627e-08 - val_loss: 1.4932e-07\n",
            "Epoch 37/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.8547e-08 - val_loss: 5.7555e-08\n",
            "Epoch 38/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.7972e-08 - val_loss: 9.3047e-08\n",
            "Epoch 39/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.8398e-08 - val_loss: 3.6930e-08\n",
            "Epoch 40/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.7424e-08 - val_loss: 7.2728e-08\n",
            "Epoch 41/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.8629e-08 - val_loss: 4.8391e-08\n",
            "Epoch 42/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.8530e-08 - val_loss: 3.4688e-08\n",
            "Epoch 43/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.7846e-08 - val_loss: 9.3838e-08\n",
            "Epoch 44/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.7196e-08 - val_loss: 4.1105e-08\n",
            "Epoch 45/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.7513e-08 - val_loss: 4.4515e-08\n",
            "Epoch 46/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.6985e-08 - val_loss: 7.6408e-08\n",
            "Epoch 47/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.7143e-08 - val_loss: 3.9267e-08\n",
            "Epoch 48/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.6317e-08 - val_loss: 4.9280e-08\n",
            "Epoch 49/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.7913e-08 - val_loss: 4.4330e-08\n",
            "Epoch 50/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.6281e-08 - val_loss: 4.3819e-08\n",
            "Epoch 51/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.6231e-08 - val_loss: 1.1837e-07\n",
            "Epoch 52/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.6792e-08 - val_loss: 4.0659e-08\n",
            "Epoch 53/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.6183e-08 - val_loss: 3.6746e-08\n",
            "Epoch 54/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.5777e-08 - val_loss: 7.2034e-08\n",
            "Epoch 55/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.5425e-08 - val_loss: 3.9773e-08\n",
            "Epoch 56/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.5994e-08 - val_loss: 6.5738e-08\n",
            "Epoch 57/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.6208e-08 - val_loss: 4.9273e-08\n",
            "Epoch 58/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.5220e-08 - val_loss: 3.2876e-08\n",
            "Epoch 59/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.5791e-08 - val_loss: 4.2153e-08\n",
            "Epoch 60/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.6083e-08 - val_loss: 3.4088e-08\n",
            "Epoch 61/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.4978e-08 - val_loss: 3.5175e-08\n",
            "Epoch 62/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.4831e-08 - val_loss: 1.0537e-07\n",
            "Epoch 63/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.3703e-08 - val_loss: 3.7252e-08\n",
            "Epoch 64/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.4919e-08 - val_loss: 4.4844e-08\n",
            "Epoch 65/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.4436e-08 - val_loss: 3.2553e-08\n",
            "Epoch 66/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.4328e-08 - val_loss: 3.7202e-08\n",
            "Epoch 67/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.4547e-08 - val_loss: 5.3361e-08\n",
            "Epoch 68/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.5155e-08 - val_loss: 3.7525e-08\n",
            "Epoch 69/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.4206e-08 - val_loss: 3.5496e-08\n",
            "Epoch 70/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.3556e-08 - val_loss: 7.7207e-08\n",
            "Epoch 71/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.4389e-08 - val_loss: 3.2496e-08\n",
            "Epoch 72/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.3998e-08 - val_loss: 3.4871e-08\n",
            "Epoch 73/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.4127e-08 - val_loss: 5.4576e-08\n",
            "Epoch 74/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.2670e-08 - val_loss: 3.1556e-08\n",
            "Epoch 75/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.3906e-08 - val_loss: 4.1661e-08\n",
            "Epoch 76/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.2739e-08 - val_loss: 3.2175e-08\n",
            "Epoch 77/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.3541e-08 - val_loss: 3.5031e-08\n",
            "Epoch 78/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.2619e-08 - val_loss: 3.6466e-08\n",
            "Epoch 79/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.3087e-08 - val_loss: 3.6138e-08\n",
            "Epoch 80/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.2194e-08 - val_loss: 3.8891e-08\n",
            "Epoch 81/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.3419e-08 - val_loss: 4.9341e-08\n",
            "Epoch 82/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.3084e-08 - val_loss: 5.4214e-08\n",
            "Epoch 83/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.2339e-08 - val_loss: 3.1294e-08\n",
            "Epoch 84/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.2946e-08 - val_loss: 4.2890e-08\n",
            "Epoch 85/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.2493e-08 - val_loss: 3.6248e-08\n",
            "Epoch 86/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.2077e-08 - val_loss: 3.7424e-08\n",
            "Epoch 87/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.1118e-08 - val_loss: 5.5350e-08\n",
            "Epoch 88/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.2565e-08 - val_loss: 4.6055e-08\n",
            "Epoch 89/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.1740e-08 - val_loss: 3.2195e-08\n",
            "Epoch 90/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.1727e-08 - val_loss: 3.9123e-08\n",
            "Epoch 91/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.2000e-08 - val_loss: 2.9429e-08\n",
            "Epoch 92/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.1151e-08 - val_loss: 3.5226e-08\n",
            "Epoch 93/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.1352e-08 - val_loss: 3.3086e-08\n",
            "Epoch 94/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.1433e-08 - val_loss: 4.3347e-08\n",
            "Epoch 95/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.1535e-08 - val_loss: 3.3841e-08\n",
            "Epoch 96/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.0379e-08 - val_loss: 2.9340e-08\n",
            "Epoch 97/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.1553e-08 - val_loss: 7.0781e-08\n",
            "Epoch 98/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.0259e-08 - val_loss: 4.0753e-08\n",
            "Epoch 99/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.0560e-08 - val_loss: 4.4462e-08\n",
            "Epoch 100/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.0198e-08 - val_loss: 3.2683e-08\n",
            "Epoch 101/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.0662e-08 - val_loss: 6.2266e-08\n",
            "Epoch 102/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 5.0602e-08 - val_loss: 9.2021e-08\n",
            "Epoch 103/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.0169e-08 - val_loss: 3.3224e-08\n",
            "Epoch 104/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.1057e-08 - val_loss: 5.0604e-08\n",
            "Epoch 105/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.0840e-08 - val_loss: 2.9027e-08\n",
            "Epoch 106/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.0741e-08 - val_loss: 3.6259e-08\n",
            "Epoch 107/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9263e-08 - val_loss: 2.8120e-08\n",
            "Epoch 108/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9930e-08 - val_loss: 3.0816e-07\n",
            "Epoch 109/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 5.0056e-08 - val_loss: 1.1131e-07\n",
            "Epoch 110/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9180e-08 - val_loss: 4.5054e-08\n",
            "Epoch 111/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9498e-08 - val_loss: 3.2435e-08\n",
            "Epoch 112/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9667e-08 - val_loss: 4.3265e-08\n",
            "Epoch 113/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.8844e-08 - val_loss: 4.5499e-08\n",
            "Epoch 114/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9649e-08 - val_loss: 2.8617e-08\n",
            "Epoch 115/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.8131e-08 - val_loss: 3.2715e-08\n",
            "Epoch 116/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9768e-08 - val_loss: 7.2191e-08\n",
            "Epoch 117/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9360e-08 - val_loss: 4.5634e-08\n",
            "Epoch 118/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.8430e-08 - val_loss: 3.3385e-08\n",
            "Epoch 119/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.8741e-08 - val_loss: 5.7692e-08\n",
            "Epoch 120/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.8905e-08 - val_loss: 3.5562e-08\n",
            "Epoch 121/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.8923e-08 - val_loss: 4.4248e-08\n",
            "Epoch 122/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.8167e-08 - val_loss: 3.8482e-08\n",
            "Epoch 123/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.9717e-08 - val_loss: 3.6618e-08\n",
            "Epoch 124/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.8122e-08 - val_loss: 6.9861e-08\n",
            "Epoch 125/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.8638e-08 - val_loss: 4.4834e-08\n",
            "Epoch 126/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.7435e-08 - val_loss: 1.0185e-07\n",
            "Epoch 127/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.8240e-08 - val_loss: 4.5867e-08\n",
            "Epoch 128/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.7956e-08 - val_loss: 7.1995e-08\n",
            "Epoch 129/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.7639e-08 - val_loss: 3.2189e-08\n",
            "Epoch 130/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.7727e-08 - val_loss: 5.6509e-08\n",
            "Epoch 131/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.8033e-08 - val_loss: 3.9497e-08\n",
            "Epoch 132/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.6992e-08 - val_loss: 5.3135e-08\n",
            "Epoch 133/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.7312e-08 - val_loss: 2.6781e-08\n",
            "Epoch 134/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.7292e-08 - val_loss: 4.2576e-08\n",
            "Epoch 135/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.7167e-08 - val_loss: 1.0387e-07\n",
            "Epoch 136/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.7425e-08 - val_loss: 6.1055e-08\n",
            "Epoch 137/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.6134e-08 - val_loss: 4.9188e-08\n",
            "Epoch 138/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.7855e-08 - val_loss: 3.2571e-08\n",
            "Epoch 139/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.6727e-08 - val_loss: 3.1839e-08\n",
            "Epoch 140/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.7200e-08 - val_loss: 7.3026e-08\n",
            "Epoch 141/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.7108e-08 - val_loss: 3.5993e-08\n",
            "Epoch 142/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.7078e-08 - val_loss: 3.5403e-08\n",
            "Epoch 143/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.6429e-08 - val_loss: 3.2685e-08\n",
            "Epoch 144/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.6565e-08 - val_loss: 1.2661e-07\n",
            "Epoch 145/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.7911e-08 - val_loss: 4.2908e-08\n",
            "Epoch 146/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5433e-08 - val_loss: 3.2763e-08\n",
            "Epoch 147/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.6860e-08 - val_loss: 3.2436e-08\n",
            "Epoch 148/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.6279e-08 - val_loss: 2.6336e-08\n",
            "Epoch 149/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5835e-08 - val_loss: 3.9180e-08\n",
            "Epoch 150/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5654e-08 - val_loss: 3.1759e-08\n",
            "Epoch 151/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5141e-08 - val_loss: 6.3029e-08\n",
            "Epoch 152/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.6451e-08 - val_loss: 2.8714e-08\n",
            "Epoch 153/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.5894e-08 - val_loss: 6.1249e-08\n",
            "Epoch 154/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4979e-08 - val_loss: 4.6391e-08\n",
            "Epoch 155/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5413e-08 - val_loss: 7.4752e-08\n",
            "Epoch 156/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.4853e-08 - val_loss: 3.9775e-08\n",
            "Epoch 157/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.4951e-08 - val_loss: 5.4999e-08\n",
            "Epoch 158/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5138e-08 - val_loss: 2.6645e-08\n",
            "Epoch 159/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5160e-08 - val_loss: 1.5247e-07\n",
            "Epoch 160/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4766e-08 - val_loss: 3.6582e-08\n",
            "Epoch 161/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4784e-08 - val_loss: 3.0178e-08\n",
            "Epoch 162/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5084e-08 - val_loss: 2.5311e-08\n",
            "Epoch 163/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5494e-08 - val_loss: 3.3685e-08\n",
            "Epoch 164/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5502e-08 - val_loss: 3.0338e-08\n",
            "Epoch 165/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4928e-08 - val_loss: 3.4216e-08\n",
            "Epoch 166/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.5117e-08 - val_loss: 2.5949e-08\n",
            "Epoch 167/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4349e-08 - val_loss: 5.1432e-08\n",
            "Epoch 168/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4625e-08 - val_loss: 2.9001e-08\n",
            "Epoch 169/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4654e-08 - val_loss: 3.3017e-08\n",
            "Epoch 170/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4805e-08 - val_loss: 5.8725e-08\n",
            "Epoch 171/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4233e-08 - val_loss: 2.0605e-07\n",
            "Epoch 172/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4393e-08 - val_loss: 4.9383e-08\n",
            "Epoch 173/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3742e-08 - val_loss: 5.5767e-08\n",
            "Epoch 174/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4013e-08 - val_loss: 3.3665e-08\n",
            "Epoch 175/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3156e-08 - val_loss: 3.4381e-08\n",
            "Epoch 176/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3755e-08 - val_loss: 4.1204e-08\n",
            "Epoch 177/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4013e-08 - val_loss: 2.8728e-08\n",
            "Epoch 178/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3782e-08 - val_loss: 5.8189e-08\n",
            "Epoch 179/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2864e-08 - val_loss: 2.9962e-08\n",
            "Epoch 180/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.4544e-08 - val_loss: 2.5989e-08\n",
            "Epoch 181/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3535e-08 - val_loss: 3.0996e-08\n",
            "Epoch 182/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2906e-08 - val_loss: 2.4442e-08\n",
            "Epoch 183/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3495e-08 - val_loss: 5.7507e-08\n",
            "Epoch 184/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3978e-08 - val_loss: 3.0334e-08\n",
            "Epoch 185/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2845e-08 - val_loss: 2.4540e-08\n",
            "Epoch 186/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2868e-08 - val_loss: 6.5595e-08\n",
            "Epoch 187/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2772e-08 - val_loss: 3.2286e-08\n",
            "Epoch 188/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2980e-08 - val_loss: 6.0516e-08\n",
            "Epoch 189/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3282e-08 - val_loss: 2.5888e-08\n",
            "Epoch 190/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2833e-08 - val_loss: 3.5886e-08\n",
            "Epoch 191/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.3416e-08 - val_loss: 3.4373e-08\n",
            "Epoch 192/200\n",
            "4500/4500 [==============================] - 9s 2ms/step - loss: 4.2590e-08 - val_loss: 3.7975e-08\n",
            "Epoch 193/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2421e-08 - val_loss: 2.4763e-08\n",
            "Epoch 194/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2398e-08 - val_loss: 2.4935e-08\n",
            "Epoch 195/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2318e-08 - val_loss: 5.6627e-08\n",
            "Epoch 196/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2222e-08 - val_loss: 3.9515e-08\n",
            "Epoch 197/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2517e-08 - val_loss: 9.5859e-08\n",
            "Epoch 198/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2509e-08 - val_loss: 2.9745e-08\n",
            "Epoch 199/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.1980e-08 - val_loss: 2.6444e-08\n",
            "Epoch 200/200\n",
            "4500/4500 [==============================] - 10s 2ms/step - loss: 4.2217e-08 - val_loss: 2.7592e-08\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72003aa490>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN-3 saving\n",
        "ann_3.save('ANN-3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvAiC-cOP8jk",
        "outputId": "9e04e2a7-2edf-430c-8734-5c15a73c9b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ANN-3/assets\n"
          ]
        }
      ]
    }
  ]
}